;Owner: k3v1n1k88
;Date Create: 1/10/2018
;This is configuration for my service List Game Ordering

[database_mysql_server]
host = 127.0.0.1
port = 7777
username = root
password = nhakhoahoc

[database_leveldb]
; If true, the database will be created if it is missing.
; Default: false
create_if_missing = true

; The DB will be created if not exist, unless ErrorIfMissing is true.
; Also, if ErrorIfExist is true and the DB exist OpenFile will returns error.
error_if_exists = false

; WriteBufferSize is the amount of data to build up in memory (backed by
; an unsorted log on disk) before converting to a sorted on-disk file.
; Larger values increase performance, especially during bulk loads. Up to
; two write buffers may be held in memory at the same time, so you may
; wish to adjust this parameter to control memory usage. Also, a larger
; write buffer will result in a longer recovery time the next time the
; database is opened.
; The default value is 4MiB.
write_buffer_size = 4194304;

; Number of open files that can be used by the DB.  You may need to
; increase this if your database has a large working set (budget
; one open file per 2MB of working set).
; Default: 1000
max_open_files = 1000

; Number of keys between restart points for delta encoding of keys.
; This parameter can be changed dynamically.  Most clients should
; leave this parameter alone.
; Default: 16
block_restart_interval = 16

; Approximate size of user data packed per block.  Note that the
; block size specified here corresponds to uncompressed data.  The
; actual size of the unit read from disk may be smaller if
; compression is enabled.  This parameter can be changed dynamically.
; Default: 4KiB
block_size = 4096;

; not equals -1 means non-null, use the specified cache for blocks.
; equals -1 mean null, leveldb will automatically create and use an 8MB internal cache.
; Default: -1
cache_size = -1

; compression is the per-block compression algorithm to use
; false => no compression
; true => snappy compression
compression = false

; VerifyChecksums is whether to verify the per-block checksums in a DB.
; The default value is false
verify_checksums = false

; If true, the implementation will do aggressive checking of the
; data it is processing and will stop early if it detects any
; errors.  This may have unforeseen ramifications: for example, a
; corruption of one DB entry may cause a large number of entries to
; become unreadable or for the entire DB to become unopenable.
; Default: false
paranoid_checks = false

[database_redis]
host = 127.0.0.1
port = 6379
password = nhakhoahoc
ssl = false
connection_timeout = 2000
socket_timeout = 2000

[database_mapping_missing_leveldb]

[database_mapping_leveldb]

[database_scoring_redis]

[database_recommendation_redis]



[connection_pool]
block_when_exhausted = true
evictor_shutdown_timeout_millis = 10000
fairness = false
max_wait_millis = -1
min_evictable_idle_time_millis = 1800000
max_total = 100
max_idle = 8
min_idle = 2
max_total_per_key = 8
min_idle_per_key = 0
max_idle_per_key = 8
num_tests_per_eviction_run = 3
soft_min_evictable_idle_time_millis = -1
test_on_create = false
test_on_borrow = false
test_on_return = false
test_while_idle = false
time_between_eviction_runs_millis = -1

;true is LIFO policy, false is FIFO
return_policy = true

[system]
point_per_login = 1
money_per_point = 10000
max_recommend_game = 5

[producer_kafka]
;help producer identify criteria request complete
acks = all  

batch.size = 16384

;list host/port to use for establishing initial connection to kafka cluster
bootstrap.servers = localhost:9092

;size of buffer memory
buffer.memory = 33554432

;type of compressing for all data generate by producer. Valid values are "none", "gzip", "snappy", "lz4"
compression.type = none

;Close idle connections after the number of milliseconds specified by this config.
connections.max.idle.ms = 600000

;true: ensure one copy in bufferstream
;false: producer retries when failure

;linger when producer send
linger.ms = 0

;The configuration controls how long KafkaProducer.send() and KafkaProducer.partitionsFor() will block
max.block.ms = 60000

;The maximum size of a request in bytes
max.request.size = 1048576

;The configuration controls the maximum amount of time the client will wait for the response of a request.
request.timeout.ms = 30000

;Setting a value greater than zero will cause the client to resend any request that fails with a potentially transient error.
retries = 0

;The amount of time to wait before attempting to retry a failed request to a given topic partition.
;This avoids repeatedly sending requests in a tight loop under some failure scenarios.
retry.backoff.ms = 100

;The size of the TCP send buffer (SO_SNDBUF) to use when sending data.
;If the value is -1, the OS default will be used.
send.buffer.bytes = -1

[consumer_kafka]
;What to do when there is no initial offset in Kafka or if
;the current offset does not exist any more on the server
; have values: "earliest", "latest","none" and anything elese(will throw exception to the consumer)
auto.offset.reset = latest

;list host/port to use for establishing initial connection to kafka cluster
bootstrap.servers = localhost:9092


;Close idle connections after the number of milliseconds specified by this config.
connections.max.idle.ms = 600000

;If true the consumer's offset will be periodically committed in the background.
enable.auto.commit = true


fetch.max.bytes = 52428800

;The maximum amount of time the server will block before answering the fetch request 
;if there isn't sufficient data to immediately satisfy the requirement given by fetch.min.bytes.
fetch.max.wait.ms = 500

fetch.min.bytes = 1 

max.partition.fetch.bytes = 1048576

;The maximum delay between invocations of poll() when using consumer group management.
max.poll.interval.ms = 300000

;The maximum number of records returned in a single call to poll().
max.poll.records = 500

;The size of the TCP receive buffer (SO_RCVBUF) to use when reading data. If the value is -1, the OS default will be used.
receive.buffer.bytes = -1

;The configuration controls the maximum amount of time the client will wait for the response of a request.
;If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted.
request.timeout.ms = 40000

;The amount of time to wait before attempting to retry a failed request to a given topic partition. 
;This avoids repeatedly sending requests in a tight loop under some failure scenarios.
retry.backoff.ms  = 100

;The size of the TCP send buffer (SO_SNDBUF) to use when sending data.
; If the value is -1, the OS default will be used.
send.buffer.bytes = -1

[system]
; To config unit time for day, week or seccond
; week => 604800 (secs)
; day => 86400 (secs)
unit_time = 604800

; Unit payment use for indentify point ( amount per one point)
; Ex: 10000 => 1d
unit_payment = 10000

; Point per login
point_per_login = 1

; base of power - use for calculate point of game
base_of_power = 2

; limit recommendation game return
limit_recommendation_game = 5

; limit scoring game return
limit_scoring_game = 5

[cache]
; make a key eligible for refresh after the specified duration, 
; but a refresh will only be actually initiated when the entry is queried.
refresh_after_write = 1

; Expire entries after the specified duration has passed since 
; the entry was created, or the most recent replacement of the value
expire_after_write = 86400

; Only expire entries after the specified duration has passed since 
; the entry was last accessed by a read or a write.
expire_after_access = 86400

; maximum size of the cache
; if zero, elements will be evicted immediately after being loaded into cache
maximum_size = 20971520

; Specifies the maximum weight of entries the cache may contain
; Ifs zero, elements will be evicted immediately after being loaded
; into cache. This can be useful in testing, or to disable caching temporarily
; This feature cannot be used in conjunction with maximumSize
maximum_weight = 1048576

[server]
host = 0.0.0.0
port = 55100